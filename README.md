# ğŸ“‰ Customer Churn Prediction (IBM Telco Dataset)

> By **Shrishti Bisht** | First End-to-End Data Science Project  
> ğŸ§  Built with industry-grade ML workflow & storytelling  
> âœ… Logistic Regression & Random Forest | ğŸ’¾ Model Saved with `joblib`

---

## ğŸ—‚ï¸ Overview

Churn in subscription businesses leads to significant revenue loss.  
This project helps **predict customer churn**, **understand why they leave**, and **provide business recommendations** using ML and EDA.

---

## ğŸ¯ Project Goals

- ğŸ”® Predict customer churn using ML classification
- ğŸ“Š Discover patterns in churn behavior via EDA
- âš–ï¸ Handle class imbalance effectively
- âš™ï¸ Build and evaluate Logistic Regression & Random Forest models
- ğŸ§¾ Deliver business-friendly insights
- ğŸ’¾ Save the final model for deployment

---

## ğŸ“ Dataset Info

- **Source**: [IBM Telco Churn Dataset (Kaggle)](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)
- **Rows**: 7,043 customers
- **Target**: `Churn` (Yes/No)
- **Features**: Demographics, billing, contract, internet & phone services

---

## ğŸ› ï¸ Tools Used

| Tool/Library | Use |
|--------------|-----|
| Python | Core programming |
| Pandas, NumPy | Data wrangling |
| Seaborn, Matplotlib | Visualizations |
| Scikit-learn | ML modeling |
| Joblib | Model saving |
| Notion | Documentation |
| Jupyter Notebook | Project development |

---

## ğŸ“Š EDA Highlights

âœ… **Key Insights:**

- ğŸ“‰ Customers with **low tenure** churn more
- ğŸ’¸ **Month-to-month** contracts show higher churn
- ğŸ’° Customers with **high monthly charges** are more likely to leave
- ğŸ§¾ **Paperless billing** customers show more churn
- ğŸ“ˆ **High total charges** = more loyal users

ğŸ–¼ï¸ *All EDA visualizations are available in the notebook*

---

## âš–ï¸ Handling Imbalanced Data

- Target class (`Churn`) is **imbalanced** (~26% churners)
- Used **Stratified Train/Test Split**
- Future scope: apply **SMOTE / class weights** for further improvement

---

## ğŸ¤– ML Models Used

### 1. Logistic Regression
- Fast, interpretable baseline
- Good for understanding relationships

### 2. Random Forest
- Captures nonlinearities & interactions
- Better recall and precision for churn class

---

## ğŸ“‰ Model Evaluation

| Model | Accuracy | Precision | Recall | F1-Score |
|-------|----------|-----------|--------|----------|
| Logistic Regression | 79.3% | 0.56 | 0.59 | 0.59 |
| Random Forest       | 82.6% | 0.67 | 0.71 | 0.69 |

âœ… **Random Forest selected** for final deployment

---

## ğŸ’¼ Business Recommendations

- ğŸ›« **Improve onboarding** for new customers (0â€“3 months)
- ğŸ” **Convert month-to-month** users to yearly plans
- ğŸ’³ **Reward loyal customers** (high total charges)
- ğŸ“ƒ **Clarify paperless billing** process to reduce confusion
- ğŸ“ Prioritize support for **high-charge, short-tenure** customers

---

## ğŸ’¾ Model Saving (Deployment Ready)

import joblib
joblib.dump(rf_model, "random_forest_churn_model.pkl")


## ğŸ§  Key Learnings
Built a complete end-to-end ML pipeline

Tackled real-world churn problem

Understood model evaluation beyond accuracy

Made data-driven business suggestions

Learned to communicate results with storytelling

## ğŸ“Œ Final Reflection
This project helped me move from basic notebooks to solving a business-centric ML problem.
It deepened my understanding of EDA, modeling, and ML deployment basics.
I'm now confident in applying this pipeline to other datasets and use-cases.
